{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8aad98e-0962-44df-a253-178c2d6d4b92",
   "metadata": {},
   "source": [
    "# Scraping AI Job Board (Live Sesssion)\n",
    "\n",
    "Code authored by: Shaw Talebi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0dabaf-2151-498f-a5c9-5ceed9f1da9c",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de062c55-e9c2-44a6-bf92-af2e76704cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d73e89-b4bb-4f9d-9535-15a2c9b0666a",
   "metadata": {},
   "source": [
    "### 1) extract job page urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738fb335-8b5a-4a35-b956-af8e71e0264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL of the job board\n",
    "base_url = \"https://aijobs.net\"\n",
    "\n",
    "# Send a GET request to fetch the webpage content\n",
    "response = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770ca963-9e55-4e8b-9ddd-939da8e4448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup object\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Extract all job post links\n",
    "job_links = []\n",
    "\n",
    "for link in soup.find_all(\"a\", class_='col py-2', href=True):\n",
    "    href = link[\"href\"]\n",
    "    if href.startswith(\"/job/\"):  # Ensure it's a job posting link\n",
    "        full_url = base_url + href\n",
    "        job_links.append(full_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b670b86-e3e6-443e-b396-b989422946ea",
   "metadata": {},
   "source": [
    "### 2) extract job data from each url\n",
    "\n",
    "Data: job title, company name, salary, location,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d8f470-b081-4829-ae1e-b3fa8f9c0e81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_job_data(url):\n",
    "    \"\"\"\n",
    "        Function to extract job data from ai-jobs.net job page\n",
    "    \"\"\"\n",
    "    \n",
    "    # Send a GET request to fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Extract job title\n",
    "    job_title = soup.find(\"h1\", class_=\"display-5 mt-4 text-break\")\n",
    "    job_title = job_title.text.strip() if job_title else \"N/A\"\n",
    "    \n",
    "    # Extract company name\n",
    "    company_name = soup.find(\"h2\", class_=\"h5\")\n",
    "    company_name = company_name.text.strip() if company_name else \"N/A\"\n",
    "    \n",
    "    # Extract salary\n",
    "    salary_span = soup.find(\"span\", class_=\"badge rounded-pill text-bg-success my-1\")\n",
    "    salary = salary_span.text.strip() if salary_span else \"N/A\"\n",
    "    \n",
    "    # Extract location\n",
    "    location_h3 = soup.find(\"h3\", class_=\"lead py-3\")\n",
    "    location = location_h3.text.strip() if location_h3 else \"N/A\"\n",
    "    \n",
    "    # Print results\n",
    "    return {\"Job Title\": job_title,\n",
    "        \"Company\": company_name,\n",
    "        \"Salary\": salary,\n",
    "        \"Location\": location\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1283da3-7182-4f2f-b2cb-0d7fd5c22302",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data_list = []\n",
    "for url in job_links:\n",
    "    job_data_list.append(extract_job_data(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbc555-cced-4076-80a4-2a818611c790",
   "metadata": {},
   "source": [
    "### 3) write data to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6a40d9-c49e-4d62-b947-376acbfd74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cfa4ef5-21f4-441f-aecc-f208a70ed066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully at: job_data.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"job_data.csv\"\n",
    "\n",
    "# Extract column names from the first dictionary (assuming all have the same keys)\n",
    "fieldnames = job_data_list[0].keys()\n",
    "\n",
    "# Write data to CSV\n",
    "with open(csv_file_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write header row\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write job data rows\n",
    "    writer.writerows(job_data_list)\n",
    "\n",
    "print(f\"CSV file saved successfully at: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8289269f-4753-4f3e-9e77-d1708dc3a983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Job Title', 'Company', 'Salary', 'Location'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
